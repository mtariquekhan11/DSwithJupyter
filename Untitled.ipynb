{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a dataset of randomly distributed values in series and plotting its histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # This is always assumed but is included here as an introduction.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "values = np.random.randn(100) # array of normally distributed random numbers\n",
    "s = pd.Series(values) # generate a pandas series\n",
    "s.plot(kind='bar', title='Normally distributed random values') # hist computes distribution\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\"\"Descriptive statistics (mean, standard deviation, number of observations, minimum, maximum,and quartiles) of numerical columns can be calculated using the .describe() method, which returns a pandas dataframe of descriptive statistics.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 1, 4, 3, 5, 2, 3, 4, 1],\n",
    "'B': [12, 14, 11, 16, 18, 18, 22, 13, 21, 17],\n",
    "'C': ['a', 'a', 'b', 'a', 'b', 'c', 'b', 'a', 'b', 'a']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['C'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quintile Analysis: with random data\n",
    "#Quintile analysis is a common framework for evaluating the efficacy of security factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.40439842 -1.99883907  1.05846999 ... -2.72051681  1.16391321\n",
      "   -0.09355325]\n",
      "  [ 2.99022738  0.70475282  0.68816812 ...  0.67153358  1.45647911\n",
      "    1.09309566]\n",
      "  [ 0.26661179  0.09139405 -0.21271218 ...  0.83498683 -0.06172875\n",
      "    0.13338354]\n",
      "  ...\n",
      "  [ 0.58031704  1.49991343  0.85241726 ... -0.64162404  1.6481826\n",
      "   -0.81027017]\n",
      "  [-0.2150292  -0.75509327  0.24534957 ... -0.95983744  0.32270648\n",
      "   -0.54264219]\n",
      "  [-1.66853157  1.71336487  0.84040112 ...  0.36503649  0.99596603\n",
      "   -0.65933852]]\n",
      "\n",
      " [[ 0.61500681  0.8041211  -1.25906613 ...  1.15994415 -0.77332085\n",
      "    1.29157132]\n",
      "  [-0.19656191  1.87681034  0.98515146 ...  0.08831308  0.811356\n",
      "    0.35574777]\n",
      "  [ 0.22858708  0.32009034 -1.3152288  ... -0.03779635 -0.21034589\n",
      "    0.5412049 ]\n",
      "  ...\n",
      "  [ 0.1132181   0.42068062  1.96075496 ... -0.91454425  0.8444869\n",
      "   -1.30313519]\n",
      "  [-0.34615875 -1.91503402  0.81036275 ...  0.24950153  0.50255248\n",
      "   -0.71892425]\n",
      "  [ 1.13421323  0.99687081  1.022552   ...  1.28790165  1.15984041\n",
      "    0.60336158]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "num_securities = 1000\n",
    "num_periods = 1000\n",
    "period_frequency = 'W'\n",
    "start_date = '2000-12-31'\n",
    "np.random.seed([3,1415])\n",
    "means = [0, 0]\n",
    "covariance = [[ 1., 5e-3],\n",
    "[5e-3, 1.]]\n",
    "# generates to sets of data m[0] and m[1] with ~0.005 correlation\n",
    "m = np.random.multivariate_normal(means, covariance,\n",
    "(num_periods, num_securities)).T\n",
    "# print(num_securities)\n",
    "# print(num_periods)\n",
    "# print(period_frequency)\n",
    "# print(start_date)\n",
    "# print(means)\n",
    "# print(covariance)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a time series index and an index representing security ids. Then use them to create dataframes for returns and signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.Index(['s{:05d}'.format(s) for s in range(num_securities)], 'ID') #generating 5digit ids\n",
    "tidx = pd.date_range(start=start_date, periods=num_periods, freq=period_frequency)#genrating date weekwise\n",
    "# print(ids)\n",
    "# print(tidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #divide m[0] by 25 to scale down to something that looks like stock returns. I also add 1e-7 to give a modest positive mean return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "security_returns\n",
      "\n",
      "              s00000    s00001    s00002    s00003    s00004    s00005  \\\n",
      "2000-12-31  0.096176 -0.079953  0.042339 -0.018918  0.061268  0.087704   \n",
      "2001-01-07  0.119609  0.028190  0.027527  0.004458 -0.038074  0.054107   \n",
      "2001-01-14  0.010665  0.003656 -0.008508 -0.032569  0.039176 -0.021409   \n",
      "2001-01-21 -0.018807  0.073145  0.050860 -0.014359  0.064312  0.015639   \n",
      "2001-01-28 -0.042030 -0.037737 -0.006546 -0.018960  0.006561  0.044594   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2020-01-26 -0.007302 -0.047325 -0.031532 -0.018795 -0.024974  0.031382   \n",
      "2020-02-02 -0.024179 -0.014062  0.019409 -0.020212  0.015903  0.004698   \n",
      "2020-02-09  0.023213  0.059997  0.034097  0.010428 -0.045196  0.006643   \n",
      "2020-02-16 -0.008601 -0.030204  0.009814  0.006949 -0.027711 -0.023916   \n",
      "2020-02-23 -0.066741  0.068535  0.033616 -0.059270  0.014945 -0.048646   \n",
      "\n",
      "              s00006    s00007    s00008    s00009  ...    s00990    s00991  \\\n",
      "2000-12-31 -0.035460  0.017163  0.073263  0.009888  ...  0.041319 -0.030691   \n",
      "2001-01-07 -0.032884  0.038913  0.007057  0.014609  ... -0.004280  0.017781   \n",
      "2001-01-14 -0.016970  0.023553 -0.000901  0.041302  ...  0.016455 -0.040018   \n",
      "2001-01-21  0.027354 -0.073704 -0.033528 -0.010829  ... -0.052184  0.013087   \n",
      "2001-01-28 -0.040747 -0.021453  0.074592 -0.014505  ...  0.059936 -0.001698   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2020-01-26  0.051800  0.013202 -0.051070 -0.052847  ... -0.073182 -0.020654   \n",
      "2020-02-02 -0.075971  0.010561  0.001332 -0.061382  ...  0.012631  0.025902   \n",
      "2020-02-09 -0.109482  0.009856 -0.066842  0.045777  ...  0.037546 -0.052403   \n",
      "2020-02-16 -0.016574 -0.017640  0.030970 -0.028164  ... -0.032329 -0.030777   \n",
      "2020-02-23  0.010509 -0.058769 -0.036115 -0.047880  ... -0.057162  0.114137   \n",
      "\n",
      "              s00992    s00993    s00994    s00995    s00996    s00997  \\\n",
      "2000-12-31 -0.039470 -0.051195 -0.078645 -0.025597  0.037650 -0.108821   \n",
      "2001-01-07 -0.021987 -0.056916  0.061362  0.025186  0.025877  0.026861   \n",
      "2001-01-14  0.011153 -0.068758 -0.010705  0.022680  0.016528  0.033400   \n",
      "2001-01-21  0.029226  0.038761 -0.006556 -0.009267 -0.037218 -0.026647   \n",
      "2001-01-28  0.000379 -0.060636  0.049518  0.065816  0.030162  0.052720   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2020-01-26  0.015293  0.019129  0.075169 -0.030021 -0.020101  0.015273   \n",
      "2020-02-02  0.000338  0.007894  0.024873 -0.066548 -0.036996  0.043029   \n",
      "2020-02-09 -0.011888 -0.046366 -0.010705  0.074089  0.005872 -0.025665   \n",
      "2020-02-16 -0.010444 -0.022287 -0.037970 -0.006120  0.059396 -0.038393   \n",
      "2020-02-23 -0.009620 -0.052951 -0.003539 -0.094639 -0.067940  0.014602   \n",
      "\n",
      "              s00998    s00999  \n",
      "2000-12-31  0.046557 -0.003742  \n",
      "2001-01-07  0.058259  0.043724  \n",
      "2001-01-14 -0.002469  0.005335  \n",
      "2001-01-21 -0.021177 -0.045578  \n",
      "2001-01-28 -0.025190 -0.070621  \n",
      "...              ...       ...  \n",
      "2020-01-26 -0.051519 -0.021642  \n",
      "2020-02-02 -0.026371 -0.022533  \n",
      "2020-02-09  0.065927 -0.032411  \n",
      "2020-02-16  0.012908 -0.021706  \n",
      "2020-02-23  0.039839 -0.026373  \n",
      "\n",
      "[1000 rows x 1000 columns]\n",
      "security_signals\n",
      "\n",
      "              s00000    s00001    s00002    s00003    s00004    s00005  \\\n",
      "2000-12-31  0.615007  0.804121 -1.259066 -1.214571 -0.324276  0.327216   \n",
      "2001-01-07 -0.196562  1.876810  0.985151 -0.926723  0.503748  1.300194   \n",
      "2001-01-14  0.228587  0.320090 -1.315229 -1.002855 -0.938554  1.193494   \n",
      "2001-01-21  0.021838  2.150821  0.296422  0.995890  1.033154  0.083256   \n",
      "2001-01-28  0.036546 -1.413908 -0.245595  0.630274 -0.559037  0.656151   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2020-01-26 -0.162879 -0.434644  0.633328 -0.414931 -0.270209 -1.767913   \n",
      "2020-02-02  0.784013  0.381631 -1.174999 -0.399188 -0.264796  1.866325   \n",
      "2020-02-09  0.113218  0.420681  1.960755 -0.935298  2.958096 -0.303960   \n",
      "2020-02-16 -0.346159 -1.915034  0.810363  0.367730 -0.668251  1.516406   \n",
      "2020-02-23  1.134213  0.996871  1.022552 -2.252357 -0.398049 -1.317668   \n",
      "\n",
      "              s00006    s00007    s00008    s00009  ...    s00990    s00991  \\\n",
      "2000-12-31  0.426072  0.139272  0.673402 -0.103074  ...  0.332627  0.360956   \n",
      "2001-01-07 -0.214991 -1.845581  0.301524 -0.313104  ...  0.365211 -3.085584   \n",
      "2001-01-14 -0.893063 -0.209387 -0.863582  0.092799  ...  0.193825 -1.228409   \n",
      "2001-01-21 -1.970607 -0.675712 -0.302665 -0.631871  ... -0.332904 -0.321327   \n",
      "2001-01-28 -0.060773  0.090760  0.608553 -0.486303  ... -0.550668 -0.130588   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2020-01-26  0.582992  1.275043 -1.431680 -0.801085  ...  0.577762 -0.287351   \n",
      "2020-02-02  0.944027 -1.781199  1.778798  1.010843  ... -0.338359 -1.159806   \n",
      "2020-02-09  0.172328  0.617746 -0.944696 -1.651316  ...  0.574075 -0.072862   \n",
      "2020-02-16 -0.905100  0.618988  0.176596  0.064423  ... -0.215217  0.654911   \n",
      "2020-02-23  1.223663  0.278888  0.220879  1.007021  ...  0.567563  1.436644   \n",
      "\n",
      "              s00992    s00993    s00994    s00995    s00996    s00997  \\\n",
      "2000-12-31 -0.647752 -0.753541 -0.987845 -2.984213 -0.387380  1.159944   \n",
      "2001-01-07  1.780146 -0.553201  1.579191 -1.262468  0.546277  0.088313   \n",
      "2001-01-14  0.189092 -0.606227 -0.767744  1.109481  0.287013 -0.037796   \n",
      "2001-01-21 -1.315745 -0.212621  0.294984  1.019872  1.201100 -0.934012   \n",
      "2001-01-28  1.303309  0.873618  0.332928  0.636598 -1.306126  0.814127   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2020-01-26 -1.219719  0.630376 -1.042780  0.501001 -1.365486 -0.794353   \n",
      "2020-02-02 -0.410813  0.407238 -0.148806 -0.895082 -0.964539 -1.952808   \n",
      "2020-02-09  0.698130 -0.430656  1.557110  1.723009  0.159789 -0.914544   \n",
      "2020-02-16 -0.794622 -0.306671 -1.232871 -0.781024 -1.554304  0.249502   \n",
      "2020-02-23  1.013995  1.949665 -0.158188 -0.240351 -0.665731  1.287902   \n",
      "\n",
      "              s00998    s00999  \n",
      "2000-12-31 -0.773321  1.291571  \n",
      "2001-01-07  0.811356  0.355748  \n",
      "2001-01-14 -0.210346  0.541205  \n",
      "2001-01-21  1.784484  0.387650  \n",
      "2001-01-28 -0.585759  0.033137  \n",
      "...              ...       ...  \n",
      "2020-01-26  0.499739  1.120174  \n",
      "2020-02-02 -0.962720 -0.362679  \n",
      "2020-02-09  0.844487 -1.303135  \n",
      "2020-02-16  0.502552 -0.718924  \n",
      "2020-02-23  1.159840  0.603362  \n",
      "\n",
      "[1000 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "security_returns = pd.DataFrame(m[0] / 25 + 1e-7, tidx, ids)\n",
    "security_signals = pd.DataFrame(m[1], tidx, ids)\n",
    "print(\"security_returns\\n\")\n",
    "print(security_returns)\n",
    "print(\"security_signals\\n\")\n",
    "print(security_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use pd.qcut to divide my signals into quintile buckets for each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcut(s, q=5):\n",
    "    labels = ['q{}'.format(i) for i in range(1, 6)]\n",
    "    return pd.qcut(s, q, labels=labels)\n",
    "cut = security_signals.stack().groupby(level=0).apply(qcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use these cuts as an index on our returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_cut = security_returns.stack().rename('returns') \\\n",
    ".to_frame().set_index(cut, append=True) \\\n",
    ".swaplevel(2, 1).sort_index().squeeze() \\\n",
    ".groupby(level=[0, 1]).mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Plot Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = plt.subplot2grid((1,3), (0,0))\n",
    "ax2 = plt.subplot2grid((1,3), (0,1))\n",
    "ax3 = plt.subplot2grid((1,3), (0,2))\n",
    "# Cumulative Returns\n",
    "returns_cut.add(1).cumprod() \\\n",
    ".plot(colormap='jet', ax=ax1, title=\"Cumulative Returns\")\n",
    "leg1 = ax1.legend(loc='upper left', ncol=2, prop={'size': 10}, fancybox=True)\n",
    "leg1.get_frame().set_alpha(.8)\n",
    "# Rolling 50 Week Return\n",
    "returns_cut.add(1).rolling(50).apply(lambda x: x.prod()) \\\n",
    ".plot(colormap='jet', ax=ax2, title=\"Rolling 50 Week Return\")\n",
    "leg2 = ax2.legend(loc='upper left', ncol=2, prop={'size': 10}, fancybox=True)\n",
    "leg2.get_frame().set_alpha(.8)\n",
    "# Return Distribution\n",
    "returns_cut.plot.box(vert=False, ax=ax3, title=\"Return Distribution\")\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Quintile Correlation with scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(returns_cut, alpha=0.5, figsize=(8, 8), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and visualize Maximum Draw Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dd(returns):\n",
    "    \"\"\"returns is a series\"\"\"\n",
    "    r = returns.add(1).cumprod()\n",
    "    dd = r.div(r.cummax()).sub(1)\n",
    "    mdd = dd.min()\n",
    "    end = dd.argmin()\n",
    "    start = r.loc[:end].argmax()\n",
    "    return mdd, start, end\n",
    "def max_dd_df(returns):\n",
    "    \"\"\"returns is a dataframe\"\"\"\n",
    "    series = lambda x: pd.Series(x, ['Draw Down', 'Start', 'End'])\n",
    "    return returns.apply(max_dd).apply(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dd_df(returns_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot it\n",
    "draw_downs = max_dd_df(returns_cut)\n",
    "fig, axes = plt.subplots(5, 1, figsize=(10, 8))\n",
    "for i, ax in enumerate(axes[::-1]):\n",
    "    returns_cut.iloc[:, i].add(1).cumprod().plot(ax=ax)\n",
    "    sd, ed = draw_downs[['Start', 'End']].iloc[i]\n",
    "    ax.axvspan(sd, ed, alpha=0.1, color='r')\n",
    "    ax.set_ylabel(returns_cut.columns[i])\n",
    "fig.suptitle('Maximum Draw Down', fontsize=18)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_time_series(df):\n",
    "    start, end = df.index.min(), df.index.max()\n",
    "    delta = end - start\n",
    "    return round((len(df) - 1.) * 365.25 / delta.days, 2)\n",
    "def annualized_return(df):\n",
    "    freq = frequency_of_time_series(df)\n",
    "    return df.add(1).prod() ** (1 / freq) - 1\n",
    "def annualized_volatility(df):\n",
    "    freq = frequency_of_time_series(df)\n",
    "    return df.std().mul(freq ** .5)\n",
    "def sharpe_ratio(df):\n",
    "    return annualized_return(df) / annualized_volatility(df)\n",
    "def describe(df):\n",
    "    r = annualized_return(df).rename('Return')\n",
    "    v = annualized_volatility(df).rename('Volatility')\n",
    "    s = sharpe_ratio(df).rename('Sharpe')\n",
    "    skew = df.skew().rename('Skew')\n",
    "    kurt = df.kurt().rename('Kurtosis')\n",
    "    desc = df.describe().T\n",
    "    return pd.concat([r, v, s, skew, kurt, desc], axis=1).T.drop('count')\n",
    "describe(returns_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
